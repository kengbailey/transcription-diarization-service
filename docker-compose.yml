services:
  # Web UI (React + Nginx)
  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: speaker-diarization-ui
    ports:
      - "5173:80"
    depends_on:
      - api
    restart: unless-stopped

  # Speaker Diarization API
  api:
    platform: linux/amd64  # Force x86_64 for PyTorch/CUDA compatibility
    build:
      context: ./api
      dockerfile: Dockerfile
      target: default  # Use 'cpu-base' for CPU-only build
    container_name: speaker-diarization-api
    ports:
      - "8008:8000"
    environment:
      # Hugging Face token (required for first model download)
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      
      # Model settings
      - DIARIZATION_MODEL=pyannote/speaker-diarization-community-1
      - EMBEDDING_MODEL=pyannote/wespeaker-voxceleb-resnet34-LM
      - MODEL_CACHE_DIR=/app/models
      
      # Qdrant connection
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - COLLECTION_NAME=speaker_embeddings
      
      # Processing settings
      - DEVICE=auto  # auto, cuda, or cpu
      - SIMILARITY_THRESHOLD=0.7
      
      # API settings
      - UPLOAD_DIR=/app/uploads
    volumes:
      # Persist downloaded models
      - ./data/models:/app/models
      # Temporary uploads
      - ./data/uploads:/app/uploads
    depends_on:
      - qdrant
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: speaker-diarization-qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
      - QDRANT__TELEMETRY_DISABLED=true
    volumes:
      - ./data/qdrant:/qdrant/storage
    restart: unless-stopped

volumes:
  models:
  uploads:
  qdrant:

networks:
  default:
    name: speaker-diarization-network
