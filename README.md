# Speaker Diarization

A complete solution for **speaker diarization**, **speaker identification**, and **transcription**. Identify who said what in your audio files with confidence.

## ğŸ¯ What It Does

Upload an audio file and get back:
- **Who spoke** - Speaker labels or identified names
- **When they spoke** - Timestamps for each speaker turn
- **What they said** - Full transcription with speaker attribution

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ **Speaker Diarization** | Detect who spoke when in any audio file |
| ğŸ” **Speaker Identification** | Match voices to registered speaker profiles |
| ğŸ“ **Transcription** | Full speech-to-text with speaker labels |
| ğŸ‘¥ **Speaker Database** | Register and manage speaker voice profiles |
| ğŸ–¥ï¸ **Modern Web UI** | Beautiful interface for all operations |
| ğŸ³ **Docker Ready** | One-command deployment with compose |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Speaker Diarization                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Web UI      â”‚     REST API        â”‚     Services        â”‚
â”‚   (React/TS)    â”‚    (FastAPI)        â”‚                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Transcribe    â”‚ â€¢ /diarize          â”‚ â€¢ pyannote.audio    â”‚
â”‚ â€¢ Speakers      â”‚ â€¢ /transcribe-*     â”‚ â€¢ wespeaker         â”‚
â”‚ â€¢ Settings      â”‚ â€¢ /speakers/*       â”‚ â€¢ Qdrant            â”‚
â”‚                 â”‚ â€¢ /identify         â”‚ â€¢ Whisper API       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- [HuggingFace Account](https://huggingface.co/) with accepted model agreements

### 1. Configure

```bash
cp .env.example .env
# Edit .env with your HuggingFace token
```

### 2. Start Services

```bash
# CPU (macOS/ARM)
docker compose -f docker-compose.cpu.yml up -d

# GPU (NVIDIA)
docker compose up -d
```

### 3. Access

| Service | URL |
|---------|-----|
| **Web UI** | http://localhost:5173 |
| **API** | http://localhost:8000 |
| **API Docs** | http://localhost:8000/docs |

## ğŸ“ Project Structure

```
speaker_diarization/
â”œâ”€â”€ api/                    # REST API (FastAPI + Python)
â”‚   â”œâ”€â”€ main.py             # API endpoints
â”‚   â”œâ”€â”€ services/           # ML services
â”‚   â””â”€â”€ README.md           # API documentation
â”‚
â”œâ”€â”€ ui/                     # Web UI (React + TypeScript)
â”‚   â”œâ”€â”€ src/                # React components
â”‚   â””â”€â”€ README.md           # UI documentation
â”‚
â”œâ”€â”€ data/                   # Persistent storage
â”‚   â”œâ”€â”€ models/             # Cached ML models
â”‚   â”œâ”€â”€ qdrant/             # Vector database
â”‚   â””â”€â”€ uploads/            # Temporary uploads
â”‚
â”œâ”€â”€ docker-compose.yml      # GPU deployment
â””â”€â”€ docker-compose.cpu.yml  # CPU deployment
```

## ğŸ“– Documentation

| Component | Description |
|-----------|-------------|
| [**API Documentation**](./api/README.md) | REST endpoints, configuration, running locally |
| [**UI Documentation**](./ui/README.md) | Features, usage guide, development |

## ğŸ› ï¸ Tech Stack

### API
- **pyannote.audio 3.1** - State-of-the-art speaker diarization
- **wespeaker** - Speaker embedding extraction
- **Qdrant** - Vector database for speaker matching
- **Whisper** - Speech-to-text transcription
- **FastAPI** - High-performance REST API

### UI
- **React 18** - Modern UI framework
- **TypeScript** - Type-safe development
- **TailwindCSS 4** - Utility-first styling
- **Vite** - Lightning-fast builds

## ğŸ’¡ Usage Examples

### Register a Speaker
```bash
curl -X POST "http://localhost:8000/speakers/register" \
  -F "file=@john_speaking.mp3" \
  -F "speaker_name=John"
```

### Transcribe with Speaker Identification
```bash
curl -X POST "http://localhost:8000/transcribe-identified" \
  -F "file=@meeting.mp3" \
  -F "num_speakers=2"
```

### Response
```json
{
  "text": "Hey everyone, welcome to the show...",
  "segments": [
    {
      "speaker": "SPEAKER_00",
      "identified_as": "John",
      "confidence": 0.85,
      "start": 0.0,
      "end": 3.2,
      "text": "Hey everyone, welcome to the show."
    }
  ],
  "speaker_mapping": {"SPEAKER_00": "John"},
  "num_speakers": 2,
  "num_identified": 1
}
```

## âš™ï¸ Configuration

Key environment variables:

| Variable | Description |
|----------|-------------|
| `HUGGINGFACE_TOKEN` | **Required** - HuggingFace API token |
| `WHISPER_API_URL` | Whisper API endpoint |
| `SIMILARITY_THRESHOLD` | Speaker matching threshold (default: 0.7) |

See [API README](./api/README.md) for full configuration options.

## ğŸ“‹ Model Licenses

Accept these HuggingFace model agreements before running:
- [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
- [pyannote/wespeaker-voxceleb-resnet34-LM](https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM)

## ğŸ¤ Contributing

Contributions welcome! See the component READMEs for development setup.

## ğŸ“„ License

This project uses:
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - MIT License
- [Qdrant](https://github.com/qdrant/qdrant) - Apache 2.0 License
